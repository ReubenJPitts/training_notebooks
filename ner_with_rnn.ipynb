{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RnWmP7oi2un"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, transformer, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.transformer = transformer\n",
        "        self.hidden_size = self.transformer.config.hidden_size\n",
        "\n",
        "    def call(self, input_ids, training=False):\n",
        "        attention_mask = tf.ones_like(input_ids, dtype=tf.int32)\n",
        "        outputs = self.transformer(input_ids=input_ids,\n",
        "                                   attention_mask=attention_mask,\n",
        "                                   training=training)\n",
        "        return outputs.last_hidden_state\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0],\n",
        "                input_shape[1],\n",
        "                self.hidden_size)"
      ],
      "metadata": {
        "id": "YHGm8WEti7hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = r'bert-base-cased'\n",
        "transformer = TFAutoModel.from_pretrained(model_name, use_safetensors=True)\n",
        "tokeniser = AutoTokenizer.from_pretrained(model_name)\n",
        "max_length = 10\n",
        "seq_length = 3\n",
        "encoder = None\n",
        "trainer = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnXT6dU2jFVI",
        "outputId": "2341c699-2525-46e1-eeb7-ffdd10fa2d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_1 = [['Peter', 'Smith'], ['George', 'Peterson'], ['Arnold', 'Schwarzenegger']]\n",
        "class_2 = [['Carter', 'Pete'], ['Pitts', 'Jacob'], ['Windsor', 'Mary']]\n",
        "tags_1 = [['B-pre', 'B-sur'], ['B-pre', 'B-sur'], ['B-pre', 'B-sur']]\n",
        "tags_2 = [['B-sur', 'B-pre'], ['B-sur', 'B-pre'], ['B-sur', 'B-pre']]\n",
        "class_id = [0, 0, 0, 1, 1, 1]\n",
        "df = pd.DataFrame(zip(class_1 + class_2, tags_1 + tags_2, class_id),\n",
        "                  columns=['value', 'tag', 'class'])\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy8HL8DLjtuA",
        "outputId": "5c37328e-f714-4c4a-f67d-92bd9c1406e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      value             tag  class\n",
            "0            [Peter, Smith]  [B-pre, B-sur]      0\n",
            "1        [George, Peterson]  [B-pre, B-sur]      0\n",
            "2  [Arnold, Schwarzenegger]  [B-pre, B-sur]      0\n",
            "3            [Carter, Pete]  [B-sur, B-pre]      1\n",
            "4            [Pitts, Jacob]  [B-sur, B-pre]      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = list(set([i for j in df['tag'] for i in j])) + ['O']\n",
        "number_of_tags = len(tags)\n",
        "print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76Au694RolIe",
        "outputId": "758a4920-c70e-49a9-e44d-e32e231d4cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-sur', 'B-pre', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hotify(lst):\n",
        "  labels = []\n",
        "  for i in lst:\n",
        "    row = [0, 0, 0]\n",
        "    row[tags.index(i)] = 1\n",
        "    labels.append(row)\n",
        "  return labels"
      ],
      "metadata": {
        "id": "wu-C1UZso2TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tokeniser(list(df['value']),\n",
        "                    padding='max_length',\n",
        "                    truncation=True,\n",
        "                    max_length=max_length,\n",
        "                    is_split_into_words=True)\n",
        "df['input_ids'] = dataset['input_ids']\n",
        "df['word_ids'] = [dataset.word_ids(i) for i in range(len(df))]\n",
        "df['labels'] = [['O' if i is None else t[i] for i in j] for j, t in zip(df['word_ids'], df['tag'])]\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rBq-AArjkgx",
        "outputId": "bae06f62-68fd-466c-ccfa-0c6edd1dbee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      value             tag  class  \\\n",
            "0            [Peter, Smith]  [B-pre, B-sur]      0   \n",
            "1        [George, Peterson]  [B-pre, B-sur]      0   \n",
            "2  [Arnold, Schwarzenegger]  [B-pre, B-sur]      0   \n",
            "3            [Carter, Pete]  [B-sur, B-pre]      1   \n",
            "4            [Pitts, Jacob]  [B-sur, B-pre]      1   \n",
            "\n",
            "                                           input_ids  \\\n",
            "0           [101, 1943, 2159, 102, 0, 0, 0, 0, 0, 0]   \n",
            "1          [101, 1667, 12092, 102, 0, 0, 0, 0, 0, 0]   \n",
            "2  [101, 7296, 20452, 24156, 11819, 7582, 9146, 1...   \n",
            "3           [101, 5007, 6377, 102, 0, 0, 0, 0, 0, 0]   \n",
            "4       [101, 15877, 1116, 5549, 102, 0, 0, 0, 0, 0]   \n",
            "\n",
            "                                            word_ids  \\\n",
            "0  [None, 0, 1, None, None, None, None, None, Non...   \n",
            "1  [None, 0, 1, None, None, None, None, None, Non...   \n",
            "2         [None, 0, 1, 1, 1, 1, 1, None, None, None]   \n",
            "3  [None, 0, 1, None, None, None, None, None, Non...   \n",
            "4  [None, 0, 0, 1, None, None, None, None, None, ...   \n",
            "\n",
            "                                              labels  \n",
            "0             [O, B-pre, B-sur, O, O, O, O, O, O, O]  \n",
            "1             [O, B-pre, B-sur, O, O, O, O, O, O, O]  \n",
            "2  [O, B-pre, B-sur, B-sur, B-sur, B-sur, B-sur, ...  \n",
            "3             [O, B-sur, B-pre, O, O, O, O, O, O, O]  \n",
            "4         [O, B-sur, B-sur, B-pre, O, O, O, O, O, O]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rolling_windows(lst, n):\n",
        "    return [lst[i:i + n] + lst[:max(0, i + n - len(lst))] for i in range(len(lst))]"
      ],
      "metadata": {
        "id": "3X3-Qjk3nme8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = []\n",
        "labels = []\n",
        "for class_id in set(df['class']):\n",
        "  subset = df[df['class'] == class_id]\n",
        "  values += rolling_windows(list(subset['input_ids']), seq_length)\n",
        "  labels += rolling_windows(list(subset['labels']), seq_length)\n",
        "labels = [[one_hotify(i) for i in j] for j in labels]\n",
        "values, labels = np.array(values, dtype=int), np.array(labels, dtype=int)\n",
        "labels = labels[:, -1, :, :]\n",
        "print(values.shape, labels.shape)\n",
        "print(values[0], labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yut1p1wMnE-A",
        "outputId": "dadcd9a9-bb35-4262-82a4-916f4eaccb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 3, 10) (6, 10, 3)\n",
            "[[  101  1943  2159   102     0     0     0     0     0     0]\n",
            " [  101  1667 12092   102     0     0     0     0     0     0]\n",
            " [  101  7296 20452 24156 11819  7582  9146   102     0     0]] [[0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenised_input = tf.keras.layers.Input(shape=(seq_length, max_length), dtype=tf.int32, name='input_ids')\n",
        "timeseries = tf.keras.layers.TimeDistributed(TransformerEncoder(transformer), name='transformer')(tokenised_input)\n",
        "reshaper = tf.keras.layers.Reshape((3, 7680))(timeseries)\n",
        "recurrent = tf.keras.layers.LSTM(768, name='recurrent')(reshaper)\n",
        "sigmoid = tf.keras.layers.Dense(max_length * number_of_tags, name='dense', activation='sigmoid')(recurrent)\n",
        "predictor = tf.keras.layers.Reshape((max_length, number_of_tags), name='shaper')(sigmoid)"
      ],
      "metadata": {
        "id": "f41g3dRgjMBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=tokenised_input,\n",
        "                       outputs=predictor)"
      ],
      "metadata": {
        "id": "RfSCoZ_ZjX1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gnkOhqwtjhGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=values,\n",
        "          y=labels,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSruSAczjiGV",
        "outputId": "20a50ab1-6cbf-41b1-8a21-60e489df579e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.8400 - loss: 0.2266 - val_accuracy: 0.8000 - val_loss: 0.3372\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step - accuracy: 1.0000 - loss: 0.1374 - val_accuracy: 0.8000 - val_loss: 0.3523\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 1.0000 - loss: 0.0964 - val_accuracy: 0.8000 - val_loss: 0.3662\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 0.0745 - val_accuracy: 0.8000 - val_loss: 0.3838\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 1.0000 - loss: 0.0574 - val_accuracy: 0.8000 - val_loss: 0.4092\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 1.0000 - loss: 0.0490 - val_accuracy: 0.8000 - val_loss: 0.4369\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0398 - val_accuracy: 0.8000 - val_loss: 0.4657\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 0.8000 - val_loss: 0.4890\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.8000 - val_loss: 0.5078\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 0.8000 - val_loss: 0.5271\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e1eb68d8710>"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    }
  ]
}